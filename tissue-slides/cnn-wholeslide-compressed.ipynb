{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting a random seed for reproducible results\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import openslide as op\n",
    "import openslide.deepzoom as deepzoom\n",
    "import cv2\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D,GlobalAveragePooling2D, BatchNormalization                                    \n",
    "from tensorflow.keras import utils, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGETS = ['normal', 'squamous', 'adenocarcinoma']\n",
    "\n",
    "train_dir = '/users/seanfrey/desktop/Train/'\n",
    "test_dir = '/users/seanfrey/desktop/Test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "def create_training_data():\n",
    "    for target in TARGETS:\n",
    "        path = os.path.join(train_dir, target)\n",
    "        class_num = TARGETS.index(target)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                # Open the file and deep zoom generator.\n",
    "                slide = op.OpenSlide(os.path.join(path, img))\n",
    "                tile = op.deepzoom.DeepZoomGenerator(osr = slide, tile_size = 8640, overlap = 0)\n",
    "                x, y = tile.level_tiles[11]\n",
    "                im = tile.get_tile(11, (x-1, y-1))\n",
    "                \n",
    "                a,b,c = np.array(im).shape\n",
    "                x2 = (b//2) - 300\n",
    "                y2 = (a//2) - 300\n",
    "                x3 = (b//2) + 300\n",
    "                y3 = (a//2) + 300\n",
    "                \n",
    "                img_array = np.array(im.crop((x2, y2, x3, y3))).astype('float32')\n",
    "                training_data.append([img_array, class_num])\n",
    "            \n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "def create_testing_data():\n",
    "    for target in TARGETS:\n",
    "        path = os.path.join(test_dir, target)\n",
    "        class_num = TARGETS.index(target)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                # Open the file and deep zoom generator.\n",
    "                slide = op.OpenSlide(os.path.join(path, img))\n",
    "                tile = op.deepzoom.DeepZoomGenerator(osr = slide, tile_size = 8640, overlap = 0)\n",
    "                x, y = tile.level_tiles[11]\n",
    "                im = tile.get_tile(11, (x-1, y-1))\n",
    "                \n",
    "                a,b,c = np.array(im).shape\n",
    "                x2 = (b//2) - 300\n",
    "                y2 = (a//2) - 300\n",
    "                x3 = (b//2) + 300\n",
    "                y3 = (a//2) + 300\n",
    "                \n",
    "                img_array = np.array(im.crop((x2, y2, x3, y3))).astype('float32')\n",
    "                testing_data.append([img_array, class_num])\n",
    "                \n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "create_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)\n",
    "    \n",
    "X_train = np.array(X_train).reshape(-1, 600, 600, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for features, label in testing_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)\n",
    "    \n",
    "X_test = np.array(X_test).reshape(-1, 600, 600, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compressed = Sequential()\n",
    "\n",
    "model_compressed.add(Conv2D(\n",
    "    filters = 16,\n",
    "    kernel_size = (3,3),\n",
    "    activation = \"relu\",\n",
    "    input_shape = (600, 600, 3)\n",
    "))\n",
    "\n",
    "model_compressed.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model_compressed.add(Conv2D(\n",
    "    filters = 64, \n",
    "    kernel_size = (2,2),\n",
    "    activation = \"relu\"))\n",
    "\n",
    "model_compressed.add(MaxPooling2D(\n",
    "    pool_size = (2,2)\n",
    "))\n",
    "\n",
    "model_compressed.add(Flatten())\n",
    "\n",
    "model_compressed.add(Dense(\n",
    "    128, \n",
    "    activation = \"relu\",\n",
    "    kernel_regularizer = regularizers.l2(0.5)\n",
    "))\n",
    "\n",
    "model_compressed.add(Dropout(0.5))\n",
    "\n",
    "model_compressed.add(Dense(\n",
    "    3, \n",
    "    activation = \"softmax\",\n",
    "    kernel_regularizer = regularizers.l2(0.5)\n",
    "))\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor = \"val_loss\",\n",
    "    min_delta = 0,\n",
    "    patience = 5\n",
    ")\n",
    "\n",
    "model_compressed.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "history_compressed = model_compressed.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size = 4,\n",
    "        validation_data = (X_test, y_test),\n",
    "        epochs = 10,\n",
    "        callbacks = [es],\n",
    "        verbose = 1,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
