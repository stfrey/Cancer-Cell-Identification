{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "# Common library imports\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import random\n",
    "import openslide as op\n",
    "import openslide.deepzoom as deepzoom\n",
    "import cv2\n",
    "\n",
    "# Imports from TensorFlow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D,\\\n",
    "                                    MaxPooling2D,GlobalAveragePooling2D, BatchNormalization                                    \n",
    "from tensorflow.keras import utils, regularizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "# Setting a random seed for reproducible results\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting targets\n",
    "TARGETS = ['normal', 'squamous', 'adenocarcinoma']\n",
    "\n",
    "# Creating a path to data directory\n",
    "train_dir = '/Train/'\n",
    "test_dir = '/Test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []\n",
    "def create_training_data():\n",
    "    for target in TARGETS:\n",
    "        path = os.path.join(train_dir, target)\n",
    "        class_num = TARGETS.index(target)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                # Open the file and deep zoom generator.\n",
    "                slide = op.OpenSlide(os.path.join(path, img))\n",
    "                tile = op.deepzoom.DeepZoomGenerator(osr = slide, tile_size = 4320, overlap = 0)\n",
    "                \n",
    "                # one off of maximal zoom\n",
    "                level = tile.level_count - 2 \n",
    "                x, y = tile.level_tiles[level]\n",
    "\n",
    "                # Creating an array\n",
    "                img_array = np.array(tile.get_tile(level, ((x//2)-1, (y//2)-1))).astype('float32')\n",
    "                training_data.append([img_array, class_num])\n",
    "            \n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "create_training_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = []\n",
    "def create_testing_data():\n",
    "    for target in TARGETS:\n",
    "        path = os.path.join(test_dir, target)\n",
    "        class_num = TARGETS.index(target)\n",
    "        for img in os.listdir(path):\n",
    "            try:\n",
    "                # Open the file and deep zoom generator.\n",
    "                slide = op.OpenSlide(os.path.join(path, img))\n",
    "                tile = op.deepzoom.DeepZoomGenerator(osr = slide, tile_size = 4320, overlap = 0)\n",
    "                \n",
    "                # 1 off of maximal zoom\n",
    "                level = tile.level_count - 2 \n",
    "                x, y = tile.level_tiles[level]\n",
    "\n",
    "                # Creating an array\n",
    "                img_array = np.array(tile.get_tile(level, ((x//2)-1, (y//2)-1))).astype('float32')\n",
    "                testing_data.append([img_array, class_num])\n",
    "            \n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "create_testing_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    X_train.append(features)\n",
    "    y_train.append(label)\n",
    "    \n",
    "X_train = np.array(X_train).reshape(-1, 4320, 4320, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for features, label in testing_data:\n",
    "    X_test.append(features)\n",
    "    y_test.append(label)\n",
    "    \n",
    "X_test = np.array(X_test).reshape(-1, 4320, 4320, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/Caskroom/miniconda/base/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 59 samples, validate on 11 samples\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(\n",
    "    filters = 16,\n",
    "    kernel_size = (3,3),\n",
    "    activation = \"relu\",\n",
    "    input_shape = (4320, 4320, 3)\n",
    "))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(\n",
    "    filters = 64, \n",
    "    kernel_size = (2,2),\n",
    "    activation = \"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size = (2,2)\n",
    "))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(\n",
    "    128, \n",
    "    activation = \"relu\",\n",
    "    kernel_regularizer = regularizers.l2(0.5)\n",
    "))\n",
    "\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(\n",
    "    3, \n",
    "    activation = \"softmax\",\n",
    "    kernel_regularizer = regularizers.l2(0.5)\n",
    "))\n",
    "\n",
    "es = EarlyStopping(\n",
    "    monitor = \"val_loss\",\n",
    "    min_delta = 0,\n",
    "    patience = 5\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    # Sparse_categorical_crossentropy will convert indexed targets to categorical targets\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['sparse_categorical_accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size = 10,\n",
    "        validation_data = (X_test, y_test),\n",
    "        epochs = 10,\n",
    "        callbacks = [es],\n",
    "        verbose = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
